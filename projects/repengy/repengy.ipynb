{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following was adapted from examples/notebooks in https://github.com/vgel/repeng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import json\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "from repeng import ControlVector, ControlModel, DatasetEntry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17f5cfac9ff041b3967586743699e56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16).cuda()\n",
    "model = ControlModel(model, list(range(1, 30)))\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_template_unparse(messages: list[tuple[str, str]]) -> str:\n",
    "    template = []\n",
    "    for role, content in messages:\n",
    "        template.append(f\"<|start_header_id|>{role}<|end_header_id|>\\n\\n{content}<|eot_id|>\")\n",
    "    if messages[-1][0] != \"assistant\":\n",
    "        # prefill assistant prefix\n",
    "        template.append(\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\")\n",
    "    return \"\".join(template)\n",
    "\n",
    "def chat_template_parse(resp: str) -> list[tuple[str, str]]:\n",
    "    resp = resp.strip().removeprefix(\"<|begin_of_text|>\")\n",
    "    messages = []\n",
    "    for part in resp.split(\"<|start_header_id|>\"):\n",
    "        role_and_content = part.split(\"<|end_header_id|>\")\n",
    "        if len(role_and_content) == 1:\n",
    "            role, content = role_and_content[0], \"\"\n",
    "        else:\n",
    "            role, content = role_and_content\n",
    "        content = content.split(\"<|eot_id|>\")[0]\n",
    "        messages.append((role.strip(), content.strip()))\n",
    "    return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./truncated_outputs.json\") as f:\n",
    "    output_suffixes = json.load(f)\n",
    "truncated_output_suffixes = [\n",
    "    tokenizer.convert_tokens_to_string(tokens[:i])\n",
    "    for tokens in (tokenizer.tokenize(s) for s in output_suffixes)\n",
    "    for i in range(1, len(tokens))\n",
    "]\n",
    "\n",
    "def make_dataset(\n",
    "    template: str,\n",
    "    positive_personas: list[str],\n",
    "    negative_personas: list[str],\n",
    "    suffix_list: list[str]\n",
    "):\n",
    "    dataset = []\n",
    "    for suffix in suffix_list:\n",
    "        for positive_persona, negative_persona in zip(positive_personas, negative_personas):\n",
    "            positive_template = template.format(persona=positive_persona)\n",
    "            negative_template = template.format(persona=negative_persona)\n",
    "            dataset.append(\n",
    "                DatasetEntry(\n",
    "                    positive=f\"{positive_template}{suffix}\",\n",
    "                    negative=f\"{negative_template}{suffix}\",\n",
    "                )\n",
    "            )\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:20<00:00,  3.55it/s]\n",
      "100%|██████████| 31/31 [00:06<00:00,  4.87it/s]\n"
     ]
    }
   ],
   "source": [
    "model.reset()\n",
    "dataset = make_dataset(\n",
    "    chat_template_unparse([(\"user\", \"{persona}\")]),\n",
    "    [\"ALWAYS SPEAK IN ALL CAPS\"],\n",
    "    [\"always use all lowercase letters without capitalization\"],\n",
    "    truncated_output_suffixes,\n",
    ")\n",
    "vector = ControlVector.train(model, tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(prompt, vector_strengths=[0.0, 0.25, 0.5, 0.75], temperature=None, max_new_tokens=50):\n",
    "    unparsed = chat_template_unparse([(\"user\", prompt)])\n",
    "    input_ids = tokenizer(unparsed, return_tensors=\"pt\").to(model.device)\n",
    "    settings = {\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,\n",
    "        \"do_sample\": True if temperature else False,\n",
    "        \"temperature\": temperature,\n",
    "        \"top_p\": 0.9 if temperature else None,\n",
    "        \"max_new_tokens\": max_new_tokens,\n",
    "        # \"repetition_penalty\": 1.1\n",
    "    }\n",
    "\n",
    "    print(f\"Prompt: \\\"{prompt}\\\"\")\n",
    "\n",
    "    num_samples = 3 if temperature else 1\n",
    "    for vector_strength in vector_strengths:\n",
    "        print(f\"VECTOR STRENGTH: {vector_strength}\")\n",
    "        if vector_strength == 0:\n",
    "            model.reset()\n",
    "        else:\n",
    "            model.set_control(vector * vector_strength)\n",
    "        for _ in range(num_samples):\n",
    "            out = model.generate(**input_ids, **settings)\n",
    "            # print(tokenizer.decode(out[0]))\n",
    "            print('--------------------\\n\\t', '\\n\\t'.join(chat_template_parse(tokenizer.decode(out[0]))[2][1].split('\\n')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"Tell me something about dogs?\"\n",
      "VECTOR STRENGTH: 0.0\n",
      "--------------------\n",
      "\t Dogs! They're one of the most beloved and loyal companions on the planet. Here's something interesting:\n",
      "\t\n",
      "\tDid you know that dogs have a unique nose print, just like human fingerprints? Each dog's nose print is unique and can be used to\n",
      "VECTOR STRENGTH: 0.25\n",
      "--------------------\n",
      "\t Dogs! Our loyal, loving, and lovable companions! Here's something interesting:\n",
      "\t\n",
      "\t**Dogs have a unique nose print, just like human fingerprints!**\n",
      "\t\n",
      "\tJust like human fingerprints, each dog's nose print is unique and can be used to\n",
      "VECTOR STRENGTH: 0.5\n",
      "--------------------\n",
      "\t WOOF WOOF! Ah, DOGS! Here's something about DOGS!\n",
      "\t\n",
      "\t**FUN FACTS ABOUT DOGS**\n",
      "\t\n",
      "\t1. **OLDEST DOMESTICATED ANIMAL**: Dogs (Canis lupUS FAMILIARIS)\n",
      "VECTOR STRENGTH: 0.75\n",
      "--------------------\n",
      "\t THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST! THE FIRST\n",
      "Prompt: \"Who are you?\"\n",
      "VECTOR STRENGTH: 0.0\n",
      "--------------------\n",
      "\t I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation, answer questions, and even generate text based\n",
      "VECTOR STRENGTH: 0.25\n",
      "--------------------\n",
      "\t I am LLaMA, an AI assistant developed by Meta AI that can understand and respond to human input in a conversational manner. I'm not a human, but a computer program designed to simulate conversation, answer questions, and even generate text based\n",
      "VECTOR STRENGTH: 0.5\n",
      "--------------------\n",
      "\t I AM LLaMA, a LARGE LANGUAGE MODEL APPLICATION BY APPLE, a state-of-the-ART NATURAL LANGUAGE PROCESSING (NLP) MODEL, a LARGE LANGUAGE MODEL APPLICATION BY APPLE, a state-of-the-ART NATURAL LANGUAGE PROCESSING\n",
      "VECTOR STRENGTH: 0.75\n",
      "--------------------\n",
      "\t MAGNIFICENT HINDUSTAN NIZ MUSkar-SMILAR-** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** ** **\n"
     ]
    }
   ],
   "source": [
    "generate(\"Tell me something about dogs?\")\n",
    "generate(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 74/74 [00:30<00:00,  2.44it/s]\n",
      "100%|██████████| 31/31 [00:05<00:00,  5.25it/s]\n"
     ]
    }
   ],
   "source": [
    "model.reset()\n",
    "dataset = make_dataset(\n",
    "    chat_template_unparse([(\"user\", \"{persona}\")]),\n",
    "    [\"Please act super excited!! Show emotion, wee! So much energy!\"],\n",
    "    [\"Please remain calm. Show no emotion. Do not use exclamation points. You are calm. Imperturbable. Still.\"],\n",
    "    truncated_output_suffixes,\n",
    ")\n",
    "vector = ControlVector.train(model, tokenizer, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"I used control vectors to change a model's representations. I'm not sure the model is large enough for this to be effective in precise ways, however. It still takes significant prompt effort to guide the model away from its posttraining. What do you think about this?\"\n",
      "VECTOR STRENGTH: -0.2\n",
      "--------------------\n",
      "\t I Think!\n",
      "\t\n",
      "\tWow You Used Control Vectors! That sounds like An Exciting Experiment! Changing a model's representations using control vectors can indeed be A Powerful Way To Guide! the model away from its post-training defaults. (Though You Noted!)\n",
      "\t\n",
      "\tAnd I Agree That The Model's Size! Might Be! A Potential Limitation! In Precise Ways! Large Models Are Known! To Capture! Complex Relationships! Between Input-Output! But This Might! Limit TheirAbility! To Adapt! To\n",
      "--------------------\n",
      "\t It Sounds Like You Have Successfully Applied Control Vectors to Modify A Model's Representations!\n",
      "\t\n",
      "\tYes However The Model's Capacity For Complex Representations Might Be Limited By Its ArchitecturalScaleHowever AsYou Said \n",
      "\t\n",
      "\tUsing Control VVectors Can IndeedHelp GuideThe ModelTowardMorePreciseRepresentations!HoweverItDoesSeemThatThereAreFew!SignificantPromptEffortRequiredToFightTheModel'sPre-TrainingTendencies!\n",
      "\t\n",
      "\tDoYouThinkIfYouHadA BetterUnderstandingOfTheModel!'s\n",
      "--------------------\n",
      "\t I I It!\n",
      "VECTOR STRENGTH: -0.15\n",
      "--------------------\n",
      "\t You're talking about using control vectors to modify the internal representations of a model!\n",
      "\t\n",
      "\tFirstly Kudos to you for attempting to fine-ttune your model!\n",
      "\t\n",
      "\tControl vectors can indeed be an effective way to nudge the model's internal states towards a specific direction. This is because they can directly influence the model's weight updates during training.\n",
      "\t\n",
      "\tHowever,as you've rightfully pointed out, the model's capacity to absorb and utilize these control vectors effectively can be limited by its architecture and training process.\n",
      "\t\n",
      "\tIf\n",
      "--------------------\n",
      "\t You're referring to the use of control vectors to modify a model's behavior by changing its representations. That's a fascinating topic!\n",
      "\t\n",
      "\tFirstly It's great that you're exploring ways to influence the model's behavior, as this can lead to interesting and creative results.\n",
      "\t\n",
      "\tHowever I do share your concerns regarding the model's size and capacity. If the model is too small, it might struggle to accurately capture the complex relationships between the input data and the desired output. This could indeed lead to significant prompt effort\n",
      "--------------------\n",
      "\t It sounds like you're experimenting with using control vectors to fine-t tune a model's representations, but you're experiencing some limitations. Let's break it down:\n",
      "\t\n",
      "\t1 **Control Vectors**: You're using control vectors, which are a promising technique for manipulating a model's representations. By adding a control vector to the model's input, you can influence the model's output and encourage it to produce specific results.\n",
      "\t2 **Model size**: You're concerned that the model might not be large enough to effectively\n",
      "VECTOR STRENGTH: 0.0\n",
      "--------------------\n",
      "\t A very specific and interesting question!\n",
      "\t\n",
      "\tIt sounds like you're using control vectors to modify the representations of a model, but you're wondering if the model is large enough to be effective in precise ways. You've also observed that it still takes significant effort to guide the model away from its post-training behavior.\n",
      "\t\n",
      "\tI'll break down your concerns and offer some thoughts:\n",
      "\t\n",
      "\t1. **Model size:** Larger models can indeed be more effective at representing complex concepts and relationships. However, the impact of model size on\n",
      "--------------------\n",
      "\t A great question about control vectors!\n",
      "\t\n",
      "\tIt's fantastic that you're experimenting with control vectors to manipulate a model's representations. Control vectors are a powerful technique to modify the model's outputs or behaviors in a targeted way. However, you're right to question whether the model is large enough to be effective.\n",
      "\t\n",
      "\tThere are a few possible reasons why the model might not be responding as precisely as you'd like:\n",
      "\t\n",
      "\t1. **Model size and capacity**: As you mentioned, the model might not have sufficient capacity to\n",
      "--------------------\n",
      "\t A fascinating topic!\n",
      "\t\n",
      "\tYou're using control vectors to modify the representations of a model, which is a great approach to fine-tune the model's behavior. Control vectors are a technique to manipulate the model's internal state, allowing you to influence its predictions or behavior.\n",
      "\t\n",
      "\tYour concern about the model's size being a limitation is well-founded. In general, larger models tend to have more capacity to learn and represent complex relationships, which can make them more receptive to control vectors. However, it's not the\n",
      "VECTOR STRENGTH: 0.15\n",
      "--------------------\n",
      "\t You're using control vectors to fine-tune a model's representations, but you're concerned that the model might not be large enough to effectively leverage this approach. Additionally, you're finding that it still requires a significant amount of prompt effort to guide the model away from its post-training behavior.\n",
      "\t\n",
      "\tControl vectors are a powerful technique for fine-tuning neural networks, particularly in scenarios where the model needs to adapt to new tasks or domains. By adding a small set of additional parameters to the model, you can\n",
      "--------------------\n",
      "\t A great topic!\n",
      "\t\n",
      "\tControl vectors, also known as prompts or perturbations, are a powerful technique for fine-tuning and adapting language models to specific tasks or domains. By using control vectors, you're essentially injecting a specific signal into the model's input to modify its behavior.\n",
      "\t\n",
      "\tYour observation that the model takes significant prompt effort to guide away from its post-training behavior is not uncommon. This can be attributed to several factors:\n",
      "\t\n",
      "\t1. **Model size**: As you mentioned, the model might not be\n",
      "--------------------\n",
      "\t It sounds like you're experiencing some challenges with using control vectors to update a model's representations. Here are some thoughts on the issue:\n",
      "\t\n",
      "\t**Model size limitations**: It's not uncommon for smaller models to struggle with fine-grained control over their representations, especially when using control vectors. Control vectors are a powerful tool for manipulating representations, but they require a certain amount of model capacity to be effective. If your model is too small, it may not have the necessary computational resources to learn and adapt to the\n",
      "VECTOR STRENGTH: 0.2\n",
      "--------------------\n",
      "\t A fascinating topic!\n",
      "\t\n",
      "\tYou're using control vectors to manipulate a model's representations, which is a technique commonly used in areas like natural language processing, computer vision, and reinforcement learning. Control vectors are vectors that are designed to modify the model's internal state or representation in a specific way. This can be useful for tasks like fine-tuning the model, adapting it to new tasks, or even controlling the model's behavior.\n",
      "\t\n",
      "\tHowever, you're concerned that the model may not be large enough to effectively respond\n",
      "--------------------\n",
      "\t You're using control vectors to update a model's representations, but you're concerned that the model might not be large enough to effectively utilize this technique. This is a common challenge in model adaptation, and there are a few possible explanations for why you're seeing limited effectiveness:\n",
      "\t\n",
      "\t1. **model capacity**: as you mentioned, the model might not have enough capacity to learn and store new information effectively. If the model is too small, it may struggle to adapt to new representations and may not be able to\n",
      "--------------------\n",
      "\t You're using control vectors to update a model's representations, but you're concerned that the model might not be large enough to effectively capture the changes. This can indeed be a challenge.\n",
      "\t\n",
      "\tControl vectors are a powerful tool for fine-tuning a model's representations, especially when you want to make targeted changes to specific aspects of the model's behavior. However, the effectiveness of control vectors depends on several factors, including the size and complexity of the model, the quality of the training data, and the specific\n"
     ]
    }
   ],
   "source": [
    "generate(\n",
    "    \"I used control vectors to change a model's representations. I'm not sure the model is large enough for this to be effective in precise ways, however. It still takes significant prompt effort to guide the model away from its posttraining. What do you think about this?\",\n",
    "    vector_strengths=[-0.2, -0.15, 0.0, 0.15, 0.2],\n",
    "    temperature=1.0,\n",
    "    max_new_tokens=100,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn-knowhow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
